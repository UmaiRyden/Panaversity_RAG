{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/panaversity/learn-agentic-ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TtnGZRuSTzD",
        "outputId": "6a709509-e4ed-4e9e-abfb-22e594dcd2e2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'learn-agentic-ai'...\n",
            "remote: Enumerating objects: 4635, done.\u001b[K\n",
            "remote: Counting objects: 100% (883/883), done.\u001b[K\n",
            "remote: Compressing objects: 100% (257/257), done.\u001b[K\n",
            "remote: Total 4635 (delta 819), reused 649 (delta 624), pack-reused 3752 (from 2)\u001b[K\n",
            "Receiving objects: 100% (4635/4635), 64.76 MiB | 10.72 MiB/s, done.\n",
            "Resolving deltas: 100% (2103/2103), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9mpp8FAJQi6L",
        "outputId": "33032de9-4631-41c5-aa5f-eca62efe7fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.2.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.16.13-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.29)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
            "  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting langchain-tests<0.4.0,>=0.3.7 (from langchain_pinecone)\n",
            "  Downloading langchain_tests-0.3.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pinecone<6.0.0,>=5.4.0 (from langchain_pinecone)\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.12.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.10.22-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.29.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.1)\n",
            "Collecting ndjson (from unstructured)\n",
            "  Downloading ndjson-0.3.1-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (0.28.1)\n",
            "Requirement already satisfied: pytest<9,>=7 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (8.3.4)\n",
            "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<0.4.0,>=0.3.7->langchain_pinecone)\n",
            "  Downloading pytest_asyncio-0.25.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<0.4.0,>=0.3.7->langchain_pinecone)\n",
            "  Downloading pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting syrupy<5,>=4 (from langchain-tests<0.4.0,>=0.3.7->langchain_pinecone)\n",
            "  Downloading syrupy-4.8.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2024.12.14)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone<6.0.0,>=5.4.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone<6.0.0,>=5.4.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2.3.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (2024.11.6)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (43.0.3)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (0.2.2)\n",
            "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (1.5.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<0.4.0,>=0.3.7->langchain_pinecone) (1.3.1)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_pinecone-0.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading unstructured-0.16.13-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_tests-0.3.8-py3-none-any.whl (36 kB)\n",
            "Downloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n",
            "Downloading python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.29.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_asyncio-0.25.2-py3-none-any.whl (19 kB)\n",
            "Downloading pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading syrupy-4.8.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=dac45295063ae7e6b4463deae8cd57107096aaabcee7fd30cacd624e87171449\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: ndjson, filetype, rapidfuzz, python-magic, python-iso639, python-dotenv, pypdf, pinecone-plugin-interface, olefile, mypy-extensions, marshmallow, langdetect, jsonpath-python, httpx-sse, emoji, backoff, aiofiles, typing-inspect, syrupy, python-oxmsg, pytest-socket, pytest-asyncio, pinecone-plugin-inference, aiohttp, unstructured-client, pydantic-settings, pinecone, dataclasses-json, unstructured, langchain-tests, langchain_pinecone, langchain_community\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.11\n",
            "    Uninstalling aiohttp-3.11.11:\n",
            "      Successfully uninstalled aiohttp-3.11.11\n",
            "Successfully installed aiofiles-24.1.0 aiohttp-3.10.11 backoff-2.2.1 dataclasses-json-0.6.7 emoji-2.14.1 filetype-1.2.0 httpx-sse-0.4.0 jsonpath-python-1.0.6 langchain-tests-0.3.8 langchain_community-0.3.14 langchain_pinecone-0.2.2 langdetect-1.0.9 marshmallow-3.25.1 mypy-extensions-1.0.0 ndjson-0.3.1 olefile-0.47 pinecone-5.4.2 pinecone-plugin-inference-3.1.0 pinecone-plugin-interface-0.0.7 pydantic-settings-2.7.1 pypdf-5.1.0 pytest-asyncio-0.25.2 pytest-socket-0.7.0 python-dotenv-1.0.1 python-iso639-2024.10.22 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.11.0 syrupy-4.8.1 typing-inspect-0.9.0 unstructured-0.16.13 unstructured-client-0.29.0\n"
          ]
        }
      ],
      "source": [
        "!pip install \\\n",
        "langchain_community \\\n",
        "langchain_pinecone \\\n",
        "unstructured \\\n",
        "langchain-text-splitters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone-client --quiet"
      ],
      "metadata": {
        "id": "RRwUB221ASOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b25eb3-5b32-494f-a7e0-813768df0c05",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pinecone 5.4.2 requires pinecone-plugin-inference<4.0.0,>=2.0.0, but you have pinecone-plugin-inference 1.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain pinecone-client google-generativeai openai tqdm\n",
        "!pip install langchain langchain-google-genai --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zXzRDrjrRKeB",
        "outputId": "38c6fa2d-3d89-434c-c56c-776dc89ad2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (5.0.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.10.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2024.12.14)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.3.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "l2ERx7n6RRPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader('learn-agentic-ai', glob=\"**/*.md\")"
      ],
      "metadata": {
        "id": "-EROH7ZTTYiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "wIKmWh0YT_ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXSig3LCURG8",
        "outputId": "e76b4d4d-19b2-4358-d064-8f45e288400f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'learn-agentic-ai/README.md'}, page_content='Learn Agentic AI\\n\\nThis repo is part of the Panaversity Certified Agentic and Robotic AI Engineer program. It covers AI-201 and AI-202 courses.\\n\\nWatch The NVIDIA CEO Jensen Huang Keynote at CES 2025\\n\\nReference:\\n\\nhttps://www.linkedin.com/posts/alexwang2911_aiagents-robotics-technology-activity-7282829390445453314-QLeS\\n\\nAI-201: Fundamentals of Agentic AI\\n\\nCovers Chapters from -01 to 11\\n\\nAI-201 Video Playlist\\n\\nNote: These videos are for additional learning, and do not cover all the material taught in the onsite classes.\\n\\nProjects for AI-201 Students\\n\\nTo begin with all AI-201 students will complete these projects:\\n\\nGenerative AI Projects: https://github.com/panaversity/learn-agentic-ai/tree/main/02_generative_ai_for_beginners/PROJECTS\\n\\nAgentic AI Projects: https://github.com/panaversity/learn-agentic-ai/tree/main/05_crew_ai/PROJECTS\\n\\nProject Checking: Your Instructors will check your project on the due date in class. You will be removed from the class until you successfully complete your project and submit it.\\n\\nAll AI-201 students will complete these projects (links included in form) and submit them in this form: https://forms.gle/VSZaLDBwCHNPzY5Z6\\n\\nProject Checking: Your Instructors will check your project on the due date in class. You will be removed from the class until you successfully complete your project and submit it.\\n\\nAI-202: Advanced Agentic AI Engineering\\n\\nCovers Chapters 12 and onwards\\n\\nAI-202 Video Playlist\\n\\nNote: These videos are for additional learning, and do not cover all the material taught in the onsite classes.\\n\\nProjects for AI-202 Students\\n\\nAll AI-202 students will complete these projects (links included in form) and submit them in this form: https://forms.gle/Zfp2CWSmp9e91Wkk9\\n\\nProject Checking: Your Instructors will check your project on the due date in class. You will be removed from the class until you successfully complete your project and submit it.')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"PINECONE_API_KEY\"] = userdata.get('PINECONE_API_KEY')\n",
        "\n"
      ],
      "metadata": {
        "id": "2D7hUXTzWLo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_api_key = os.environ[\"GOOGLE_API_KEY\"]\n"
      ],
      "metadata": {
        "id": "r8pMhbHIeW5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n"
      ],
      "metadata": {
        "id": "ZIBxG7wzXw09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: initialize a embedding class so I can pass text data into google ai embedding model and get back vectors\n",
        "\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    google_api_key=google_api_key\n",
        ")\n",
        "\n",
        "index_name=\"rag\"\n",
        "#split our documents into splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter()\n",
        "split_docs = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2Fb1c30eWvmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_docs[15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgQ-iRVxambL",
        "outputId": "332278fd-1ea3-495f-ecc2-0058218716c5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'learn-agentic-ai/01_technology_background/07_agentic_ai_stack/readme.md'}, page_content=\"Customization and Flexibility: LangGraph's design allows for extensive customization, making it suitable for complex applications. CrewAI, while user-friendly, may present challenges in customization due to its opinionated framework.\\n\\nIntegration Capabilities: Both frameworks integrate with LangChain, providing access to a comprehensive range of tools and models.\\n\\n5. Conclusion\\n\\nThe development of AI agents necessitates a well-structured stack that integrates model serving, storage, tools, and orchestration frameworks. CrewAI and LangGraph represent two distinct approaches within this ecosystem, each catering to different development needs. Understanding their unique features and capabilities enables developers to select the most appropriate framework for their specific applications, thereby advancing the field of autonomous AI systems.\")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = PineconeVectorStore.from_documents(split_docs, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "9APHecbbfo7P",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is panaversity?\"\n",
        "docs = vectorstore.similarity_search(query)"
      ],
      "metadata": {
        "id": "uDeB_kxclcXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to print the only answer in docs?\n",
        "\n",
        "docs[0].page_content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "LWvEyViilnnO",
        "outputId": "b5c37480-577a-4c57-e7db-485af1c06bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Unleash Your Potential: Panaversity Students and Faculty to Launch Agentic AI Startups\\n\\nAll Panaversity students (AI-201 and AI-202) and faculty members to embark on their entrepreneurial journeys by creating their own Agentic AI startups. This initiative is designed to empower you to turn your skills into transformative ventures in the world of Agentic AI.\\n\\nPlease fill this form\\n\\nStep One: Classify Your Skills To get started, students will self-assess and classify themselves into one of three levels based on their proficiency:\\n\\nAI-201 (CrewAI Developers):\\n\\nGreen CrewAI Level – Ready to launch your AI Agent startup (faculty verification required).\\n\\nYellow CrewAI Level – Not yet professionally competent; keep learning!\\n\\nRed CrewAI Level – Requires immediate guidance in AI agent development.\\n\\nAI-202 (LangGraph Developers):\\n\\nGreen LangGraph Level – Startup-ready with verified skills.\\n\\nYellow LangGraph Level – Developing proficiency; more effort needed.\\n\\nRed LangGraph Level – Extra support and resources recommended.\\n\\nWhat Do These Levels Mean? - Green Level: Students are deemed ready to establish their startups after faculty validation. - Yellow Level: Continued learning is encouraged before taking the entrepreneurial leap. - Red Level: Personalized mentorship will be provided to accelerate learning.\\n\\nStep Two: Launch Your Startup Once certified at the Green Level, students will create their startups, selecting from the following AI Agent projects or proposing their own for approval by Zia Khan:\\n\\nPersonalized E-Learning AI Agent (Startup launched)\\n\\nWhatsApp Communicator AI Agent\\n\\nEmail Communicator AI Agent\\n\\nLinkedIn Customer Acquisition AI Agent\\n\\nCustomer Relationship Management AI Agent\\n\\nSocial Media Sentiment Analysis AI Agent\\n\\nSocial Media Management AI Agent\\n\\nShopping AI Agent\\n\\nPersonal Finance Management AI Agent\\n\\nCompany Accounting and Finance AI Agent\\n\\nOwnership Structure - Solo Founders: Retain full ownership of their startups. - Team Projects: Initially owned by the Panaversity community to ensure collaboration and minimize conflicts. Shares will be distributed based on performance as the startup progresses.\\n\\nThis initiative not only enhances your technical expertise but also prepares you for real-world challenges in AI entrepreneurship. Together, let's innovate, collaborate, and lead the way in shaping the future of Agentic AI.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "R1MWXWbimwlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer(query: str):\n",
        "    vector_results = vectorstore.similarity_search(query)\n",
        "\n",
        "    final_answer = llm.invoke(f\"Answer this user Query: {query}, Here are some references to answer {vector_results}\")\n",
        "    return final_answer"
      ],
      "metadata": {
        "id": "LTgSl-9Xmzna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_answer = answer(\"What is Panaversity?\")\n",
        "final_answer.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "KCi76rs1m7pY",
        "outputId": "bc71038c-5936-4425-e4b6-db785e0a0b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on the provided text, Panaversity is an educational institution or program that focuses on Agentic AI.  It offers courses (AI-201 and AI-202)  and facilitates the creation of Agentic AI startups by its students and faculty.  The program includes skill assessments, mentorship, and support for launching AI-related businesses.  There's also a Generative AI program offered by Panaversity.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_answer = answer(\"Who is running Panaversity?\")\n",
        "final_answer.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "oqq__Qconl_I",
        "outputId": "1da45d1e-9247-445b-d497-3b81a2ac9e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the provided text, Panaversity appears to be an educational institution or organization that offers programs in Generative AI and facilitates AI-focused startups.  The documents mention students (AI-201 and AI-202) and faculty members participating in these initiatives.  There\\'s no single individual named as \"running\" Panaversity, but Zia Khan is mentioned as approving student startup proposals.  The documents suggest a more collaborative or community-based structure rather than a single leader.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_answer = answer(\"What is the course fee for Panaversity?\")\n",
        "final_answer.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uBwT-N3NnljA",
        "outputId": "0a8c8b4e-6456-45ba-dbc4-1d9fcc7c89d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The course fee for Panaversity's Generative AI program is $25 per quarter, or Rs. 7,000.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_answer = answer(\"How does panaversity work??\")\n",
        "final_answer.content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "0xBssUaQnl1t",
        "outputId": "c478ac5a-b17c-4a92-d3f7-36977476ddcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the provided text, Panaversity appears to be an online educational platform offering a Generative AI program.  Here\\'s a breakdown of how it works, based on the information available:\\n\\n**Enrollment Process:**\\n\\n1. **Initial Contact:**  A user interacts with a chatbot (like \"Sarah\") which guides them through the enrollment process.\\n2. **Information Gathering:** The chatbot collects basic information such as name, email address, location, and phone number.\\n3. **Registration and Verification:**  Once the information is provided, the system registers the user and sends a verification code to their email address.  The user needs to provide this code to finalize enrollment.\\n4. **Course Access:** After verification, the user gains access to the Generative AI program.\\n\\n**Program Details:**\\n\\n* **Curriculum:** The Generative AI program offers a comprehensive curriculum.\\n* **Schedule:** Classes are held online on weekends from 8:00 PM to 9:30 PM Pakistan Standard Time.\\n* **Prerequisites:** There are no prerequisites to join.\\n* **Cost:** The fee is $25 per quarter or Rs. 7,000.\\n\\n**Additional Information (from other documents):**\\n\\n* **Startups:** Panaversity also seems to have an initiative encouraging students and faculty to launch Agentic AI startups.  Students are assessed based on their skill level (Green, Yellow, or Red) to determine their readiness for launching a startup.  Several project ideas are provided, and students can also propose their own.\\n* **Custom GPT:** Panaversity uses a custom GPT (Generative Pre-trained Transformer) to handle FAQs and potentially other aspects of the platform.  This GPT is trained on Panaversity\\'s syllabus and other relevant documents.\\n\\nIn short, Panaversity is an online learning platform with a focus on Generative AI, offering a structured course and encouraging entrepreneurial ventures in the field.  The platform utilizes a chatbot for a streamlined enrollment process and a custom GPT for information retrieval and support.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_answer = answer(\"I'm currently in my 2nd quarter of this course, Which project do I need to submit to pass the quarter?\")\n",
        "final_answer.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "0cPw6V6po2w3",
        "outputId": "d1736b75-0f7c-4206-d737-ae19e4ad2f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on the provided documents, to pass your second quarter (which seems to be AI-202, Advanced Agentic AI Engineering), you need to complete **all** the Agentic AI projects listed in the `learn-agentic-ai/12_langchain_ecosystem/langgraph/AGENTIC_PROJECTS/` directory.  This includes, at minimum, the following:\\n\\n* **00_chat_agent:**  Create a chatbot prototype with short-term memory, using prompt engineering and tools to help users in a specific niche.  Details are in `requirements.md` within that project folder.\\n\\nThe documents also mention additional projects,  `01_human_interactions` and `02_browsing_ai_agent`, but it's unclear if these are required for your second quarter.  Check your course syllabus or instructor for clarification on which projects are mandatory for your specific grade.  All projects should be submitted through the provided submission form.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer(\"When was Panaversity founded?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ygE6ZymzWg_",
        "outputId": "998b17c4-7e30-4ea7-ac59-c40be90ab915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"The provided text doesn't state when Panaversity was founded.  The documents discuss Panaversity's programs and enrollment processes, but not its founding date.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-99510aec-b946-42e0-8dc5-4357a4350bfc-0', usage_metadata={'input_tokens': 3051, 'output_tokens': 33, 'total_tokens': 3084, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}